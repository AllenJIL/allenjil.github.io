---
layout: post
title: "BigQuery and SQL"
description: "Cheating page of BigQuery and SQL"
date: 2019-08-12
tag: Kaggle
---
[Intro to SQL]: <https://www.kaggle.com/learn/intro-to-sql> "Intro to SQL"



> Most notes and code are from:  
> [Intro to SQL]  
 

**********
<!-- MarkdownTOC -->

- [Introduction](#introduction)
    - [Table schema](#table-schema)
- [Big Datasets](#big-datasets)
    - [Estimate the size of query](#estimate-the-size-of-query)
    - [Limit scan data](#limit-scan-data)
- [SELECT FROM WHERE](#select-from-where)
    - [SELECT FROM](#select-from)
    - [WHERE](#where)
    - [More queries](#more-queries)

<!-- /MarkdownTOC -->

**********

<a id="introduction"></a>
## Introduction

```python

from google.clound import bigquery  

# Create a 'Client' object
client = bigquery.Client()  

# Construct a reference to the 'hacker_news' dataset
dataset_ref = client.dataset('hacker_news', project = 'bigquery-public-data')  

# API request - fetch the dataset
dataset = clinet.get_dataset(dataset_ref)  

# List all the tables in the 'Hacker_news' dataset
tables = list(client.list_tables(dataset))  

# Print names of all tables in the dataset
for table in tables:  
	print (table.table_id)  

```

* Similar to fetch a dataset, also can fetch a table  

```python
# Construct a reference to the 'full' table
table_ref = dataset_ref.table('full')  

# API request - fetch the table
table = client.get_table(table_ref)  
```

<img src="https://i.imgur.com/biYqbUB.png">  

<a id="table-schema"></a>
### Table schema


* Print information on all the columns in the "full" table in the "hacker_news" dataset  

```python
table.schema  
```

* Each `SchemaField` tells us about the specific column which contains 'name', 'fiel type', 'mode', and 'description'  

* `list_rows()` is to show the lines of the table and converts to a pandas DataFrame with `to_dataframe()` mehtod  

```python
# Preciew the first five lines of the 'full' table
client.list_rows(table, max_results=5).to_dataframe()
```

```python
# Preview the first five entries in the 'by' column of the 'full' table
client.list_rows(table, selected_fields=table.schema[:1],max_results=5).to_dataframe()  
```

<a id="big-datasets"></a>
## Big Datasets

<a id="estimate-the-size-of-query"></a>
### Estimate the size of query

```python
# Query to get the score column from every row where the type column has value "job"
query = """
        SELECT score, title
        FROM `bigquery-public-data.hacker_news.full`
        WHERE type = "job" 
        """

# Create a QueryJobConfig object to estimate size of query without running it
dry_run_config = bigquery.QueryJobConfig(dry_run=True)

# API request - dry run query to estimate costs
dry_run_query_job = client.query(query, job_config=dry_run_config)

print("This query will process {} bytes.".format(dry_run_query_job.total_bytes_processed))
```

<a id="limit-scan-data"></a>
### Limit scan data

```python  
# Only run the query if it's less than 1 MB
ONE_MB = 1000*1000

# Also can increase to 1 GB
# ONE_GB = 1000*1000*1000
safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_MB)

# Set up the query (will only run if it's less than 1 MB)
safe_query_job = client.query(query, job_config=safe_config)

# API request - try to run the query, and return a pandas DataFrame
safe_query_job.to_dataframe()
```

<a id="select-from-where"></a>
## SELECT FROM WHERE

<a id="select-from"></a>
### SELECT FROM

```python
# to select the Name column (from the full table in the hacker_news database in the bigquery-public-data project)
query = """
        SELECT Name  
        FROM 'bigquery-public-data.hacker_news.full'  
        """  
        # The triple quotation marks makes everything inside them be a single string  
```

<a id="where"></a>
### WHERE

```python
# Get the Name column which the News about Google
query = """
        SELECT score  
        FROM `bigquery-public-data.hacker_news.full`  
        WHERE type = "job"
        """
```

```python
# Set up the query
query_job = client.query(query)  
```

```python
# API request - run the query, and return a pandas DataFrame
us_cities = query_job.to_dataframe()  

# Then we can use any other DataFrame

# The five cities have the most measurements
us_cities.city.value_counts().head()  
```

<a id="more-queries"></a>
### More queries

```python
# want multiple columns
query = """
        SELECT score, title
        """
# Wannt all columns
query = """
        SELECT *  
        """ 

```

